{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.attrs import ORTH, LEMMA, NORM, TAG\n",
    "from datetime import datetime, timedelta\n",
    "from spacy.attrs import ORTH, LEMMA, NORM, TAG\n",
    "from clean import replace_emoticons, clean_text, clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy nlp library\n",
    "nlp = spacy.load('en_core_web_sm',parser=False, entity=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv(\"@JoeBiden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv(\"@BernieSanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv(\"@ewarren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv(\"@KamalaHarris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(username):\n",
    "\n",
    "    # Import candidate's tweets into a dataframe\n",
    "    twitter_df = pd.read_csv(f\"data/{username}.csv\", error_bad_lines=False)\n",
    "\n",
    "    # Convert date from UTC to EDT\n",
    "    twitter_df[\"tweet_date\"] = twitter_df[\"tweet_date\"].\\\n",
    "        map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S') - timedelta(hours=4))\n",
    "\n",
    "    # Delete tweets from more than a week from first tweet\n",
    "    max_date = twitter_df.tweet_date.min() + timedelta(days = 7)\n",
    "    twitter_df = twitter_df[twitter_df[\"tweet_date\"] < max_date]\n",
    "    \n",
    "    # Clean text of tweets using previously defined clean_tweet function\n",
    "    twitter_df[\"tweet\"] = twitter_df[\"tweet\"].map(lambda x: clean_tweet(x, nlp))\n",
    "    \n",
    "    # For now, we are going to save off cleaned csv, but in the \"real code\", we are giong to not do this in separate steps\n",
    "    twitter_df.to_csv(f\"data/{username}_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
