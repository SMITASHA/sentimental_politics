{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import re\n",
    "import spacy\n",
    "from spacy.attrs import ORTH, LEMMA, NORM, TAG\n",
    "import pandas as pd\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emoticons(string):\n",
    "    \"\"\"Replace emoticons with positive or negative words\"\"\"\n",
    "\n",
    "    \n",
    "    # Define emoticons to be replaced\n",
    "    emoticons ={'Good': [':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)',\\\n",
    "                         ':}', ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D',\\\n",
    "                         '=D', '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P',\\\n",
    "                         ':P', 'X-P','x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)',\\\n",
    "                         '>;)', '>:-)', '<3'],\n",
    "                'Bad': [':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\\\n",
    "                        ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\\\n",
    "                        ':c', ':{', '>:\\\\', ';(']}\n",
    "    \n",
    "    # If a string in a tweet is an emoticon, replace that emoticon with positive/negative word\n",
    "    for emoticon_key, emoticon_val in emoticons.items():\n",
    "        if string in emoticon_val:\n",
    "            string = emoticon_key\n",
    "            break\n",
    "        \n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \"\"\"Cleans given string from tweet to prepare for using in machine learning model\"\"\"\n",
    "    \n",
    "\n",
    "    # Replace emoticons\n",
    "    string = replace_emoticons(string)\n",
    "    # Replace emojis\n",
    "    string = re.sub(r'[^\\x00-\\x7F]+','', string)\n",
    "    # Remove HTML special entities\n",
    "    string = re.sub(r\"\\&\\w*;\",\" \", string)\n",
    "    # Remove hyperlinks\n",
    "    string = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))\\S+\",\\\n",
    "                    \"\", string)\n",
    "    # Remove twitter usernames\n",
    "    string = re.sub(r\"@[^\\s]+\",\"\", string)\n",
    "    # Remove numbers\n",
    "    string = re.sub(\"\\d+\", \"\", string)\n",
    "    # Remove special characters\n",
    "    string = re.sub(r\"[^\\w\\s]\", \" \", string)\n",
    "    string = re.sub(r\"\\_\", \" \", string)\n",
    "    # Remove 1 letter words\n",
    "    string = re.sub(r\"\\W*\\b\\w\\b\", \"\", string)\n",
    "    # Remove leftover whitespace\n",
    "    if string:\n",
    "        string = \" \".join(string.split())\n",
    "    # Make lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \"\"\"Lemmatizes tweet and replaces stop words\"\"\"\n",
    "    \n",
    "    # Declare global variable \n",
    "    global wordcount\n",
    "    \n",
    "    # Add customized stop words\n",
    "    nlp.Defaults.stop_words |= {\"-PRON-\",\"joe\", \"biden\", \"bernie\",\"sanders\", \"elizabeth\", \"warren\", \\\n",
    "                                \"kamala\", \"harris\", \"s\", \"ve\", \"twitter\", \"tweet\", \"come\", \"year\", \"know\"}\n",
    "    \n",
    "    # Clean tweet\n",
    "    tweet = clean_text(tweet)\n",
    "    \n",
    "    # Create empty list for cleaned text\n",
    "    text = []\n",
    "    \n",
    "    # Lemmatize tweet\n",
    "    doc = nlp(tweet)\n",
    "    for token in doc:\n",
    "        string = token.lemma_\n",
    "        # Verify not a stop word\n",
    "        if string not in nlp.Defaults.stop_words:\n",
    "            text.append(string)\n",
    "            if string not in wordcount:\n",
    "                wordcount[string] = 1\n",
    "            else:\n",
    "                wordcount[string] += 1\n",
    "\n",
    "    # If no text is left, return null; otherwise, return cleaned tweet as single string\n",
    "    if not text:\n",
    "        return(None)\n",
    "    else:\n",
    "        return(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"@JoeBiden\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(f\"data/{username}.csv\", error_bad_lines=False)\n",
    "twitter_df = twitter_df[:1000]\n",
    "twitter_df[\"tweet\"] = twitter_df[\"tweet\"].map(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy nlp library\n",
    "nlp = spacy.load('en_core_web_sm',parser=False, entity=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import training dataset to test cleaning script on, and select random sample\n",
    "df = pd.read_csv(\"Resources/sent_analysis_dataset.csv\", error_bad_lines=False)\n",
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount = {}\n",
    "df[\"clean\"] = df[\"SentimentText\"].map(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump :  161\n",
      "like :  119\n",
      "want :  118\n",
      "know :  101\n",
      "good :  93\n",
      "day :  91\n",
      "think :  87\n",
      "people :  81\n",
      "tonight :  80\n",
      "need :  79\n",
      "time :  78\n",
      "win :  74\n",
      "don :  71\n",
      "night :  69\n",
      "debate :  68\n",
      "vote :  67\n",
      "candidate :  67\n",
      "come :  66\n",
      "love :  61\n",
      "work :  59\n",
      "right :  56\n",
      "feel :  51\n",
      "year :  51\n",
      "bad :  48\n",
      "democrat :  48\n",
      "tell :  47\n",
      "plan :  45\n",
      "president :  45\n",
      "great :  43\n",
      "let :  43\n",
      "miss :  42\n",
      "thank :  42\n",
      "lose :  41\n",
      "look :  41\n",
      "dem :  41\n",
      "talk :  40\n",
      "lol :  39\n",
      "state :  39\n",
      "way :  38\n",
      "hope :  37\n",
      "pay :  36\n",
      "today :  35\n",
      "oh :  35\n",
      "black :  35\n",
      "new :  34\n",
      "thing :  34\n",
      "try :  33\n",
      "country :  33\n",
      "racist :  32\n",
      "demdebate :  32\n",
      "mean :  31\n",
      "away :  31\n",
      "support :  31\n",
      "beat :  30\n",
      "big :  30\n",
      "american :  30\n",
      "election :  30\n",
      "tomorrow :  29\n",
      "stop :  29\n",
      "america :  29\n",
      "obama :  29\n",
      "leave :  28\n",
      "home :  28\n",
      "wait :  28\n",
      "run :  28\n",
      "sad :  27\n",
      "man :  27\n",
      "start :  27\n",
      "guy :  27\n",
      "sure :  26\n",
      "find :  26\n",
      "help :  26\n",
      "believe :  26\n",
      "ya :  26\n",
      "lot :  26\n",
      "care :  26\n",
      "policy :  26\n",
      "healthcare :  26\n",
      "head :  25\n",
      "money :  25\n",
      "speak :  25\n",
      "friend :  24\n",
      "follow :  24\n",
      "doesn :  24\n",
      "maybe :  24\n",
      "use :  24\n",
      "ask :  24\n",
      "issue :  24\n",
      "democraticdebate :  24\n",
      "white :  23\n",
      "hear :  23\n",
      "ticket :  23\n",
      "party :  23\n",
      "fight :  23\n",
      "poll :  22\n",
      "watch :  22\n",
      "actually :  22\n",
      "old :  22\n",
      "sorry :  21\n",
      "damn :  21\n"
     ]
    }
   ],
   "source": [
    "# Print 50 most common words\n",
    "word_counter = collections.Counter(wordcount)\n",
    "for word, count in word_counter.most_common(100):\n",
    "    print(word, \": \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
